{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = \"UJCVt2rNOgs\"\n",
    "text_language = \"en\"\n",
    "\n",
    "transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "transcript = transcript_list.find_generated_transcript([text_language]).fetch()\n",
    "# Convierte los tiempos start a un formato standard\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for t in transcript:\n",
    "\n",
    "    hours = int(t[\"start\"] // 3600)\n",
    "    min = int((t[\"start\"] // 60) % 60)\n",
    "    sec = int(t[\"start\"] % 60)\n",
    "    t[\"start\"] = f\"{hours:02d}:{min:02d}:{sec:02d}\"\n",
    "\n",
    "    text += f'\\n{t[\"text\"]} - (start:{t[\"start\"]})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Could you divide the video into sequential parts? Tell me the time they starts and explain each part.', 'result': \" Sure, the video can be divided into the following parts:\\n- 00:00:59 - 00:01:03: The speaker talks about feeling surreal with the state-of-the-art M2 and R1 chips inside the product and its ability to deliver images quickly.\\n- 00:01:03 - 00:01:10: The speaker mentions the features of the product, such as built-in cameras, microphones, and seamless finger navigation.\\n- 00:01:10 - 00:01:34: The speaker expresses their surprise and excitement about the product's intuitiveness and ease of use, specifically for tasks like using FaceTime and browsing Safari.\\n- 00:01:34 - 00:01:52: The speaker discusses the popularity and anticipation for the product, as well as its limited availability at launch.\\n- 00:01:52 - 00:02:38: The speaker talks about their personal desire to use the product as a large monitor for watching movies or videos.\\n- 00:02:38 - 00:02:58: The speaker mentions the potential difficulties of using Netflix through the Safari browser and talks about the product's focus on non-gaming purposes.\\n- 00:02:\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain,RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "template = \"\"\"Answer the question in your own words from the \n",
    "context given to you. The context given to you is the transcript of a video.\n",
    "If questions are asked where there is no relevant context available, please answer from \n",
    "what you know.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Human: {question}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate (\n",
    "\n",
    "input_variables=[\"context\",  \"question\"], template=template)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\",chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "#memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), chain_type_kwargs={'prompt': prompt}) #memory=memory,\n",
    "\n",
    "question1= \"Could you divide the video into sequential parts? Tell me the time they starts and explain each part.\"\n",
    "result1 = qa({\"query\": question1})\n",
    "print(result1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
